# -*- coding: utf-8 -*-
"""GToolA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WftQ84WCFryk847WYhOusv1D262PU66D
"""

!git clone https://github.com/ElHaban3ro/GToolA
import zipfile
dataset_export = zipfile.ZipFile('/content/GToolA/Images_samples.zip') # Load zip file.
dataset_export.extractall('/content/')

#TODO: Preparar dataset
import os 
from PIL import Image
import numpy as np
from keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
import matplotlib.pyplot as plt



new_samples = 2

train_files = os.listdir('/content/Images/Train')
train_x = [] # Imagenes
train_y = [] # Labels

for image_t in train_files:
  img = Image.open(f'/content/Images/Train/{image_t}').resize((28, 28)) # Esto se puede 
  # variar para obtener mayor resolución para las imagenes de entrenamiento y validación. 'L'

    
  for i in range(new_samples):
    datagen = ImageDataGenerator(
        rotation_range = 40,
        shear_range = 0.3,
        zoom_range = 0.3,
        vertical_flip = True,
        brightness_range = (0.2, .6),

        width_shift_range = 0.2,
        height_shift_range = 0.2
    )

    img_array = np.asarray(img)
    img_array = img_array[np.newaxis]
    
    new_image = datagen.flow(img_array, batch_size = 1)
    train_x.append(new_image[0][0, :, :, :])




  if 'alt' in image_t:
    img_a = train_x.append(np.asarray(img))
    train_y.append(0) # Las etiquetas consisten en numeros. Las Redes no entienden de letras.
    for a_appends in range(new_samples):
      train_y.append(0)


  elif 'y' in image_t[0]:
    img_a = train_x.append(np.asarray(img))
    train_y.append(1)
    
    for a_appends in range(new_samples):
      train_y.append(1)


  elif 'n' in image_t[0]:
    img_a = train_x.append(np.asarray(img))
    train_y.append(2)

    for a_appends in range(new_samples):
      train_y.append(2)


  elif 'h' in image_t[0]:
    img_a = train_x.append(np.asarray(img))
    train_y.append(3)

    for a_appends in range(new_samples):
      train_y.append(3)

train_data = (train_x, np.array(train_y)) # Tupla con datos las imagenes como array y sus etiquetas.

val_files = os.listdir('/content/Images/Validation')
val_x = [] # Imagenes
val_y = [] # Labels

for image_v in val_files:
  img_val = Image.open(f'/content/Images/Validation/{image_v}').resize((28, 28)) # Esto se puede 
  # variar para obtener mayor resolución para las imagenes de entrenamiento y validación.


      
  for i in range(1):
    datagen_val = ImageDataGenerator(
        rotation_range = 50,
        shear_range = 0.5,
        zoom_range = 0.5,
        vertical_flip = True,
        brightness_range = (0.2, .5),

        width_shift_range = 0.2,
        height_shift_range = 0.2
    )

    img_val_array = np.asarray(img_val)
    img_val_array = img_val_array[np.newaxis]
    
    new_val_image = datagen_val.flow(img_val_array, batch_size = 1)
    val_x.append(new_val_image[0][0, :, :, :])

    

  if 'alt' in image_v:
    img_a = val_x.append(np.asarray(img_val))
    val_y.append(0)

    for i in range(1):
      val_y.append(0)

  elif 'y' in image_v[0]:
    img_a = val_x.append(np.asarray(img_val))
    val_y.append(1)

    for i in range(1):
      val_y.append(1)

  elif 'n' in image_v[0]:
    img_a = val_x.append(np.asarray(img_val))
    val_y.append(2)

    for i in range(1):
      val_y.append(2)


  elif 'h' in image_v[0]:
    img_a = val_x.append(np.asarray(img_val))
    val_y.append(3)

    for i in range(1):
      val_y.append(3)

val_data = (val_x, np.array(val_y))

from keras.preprocessing.image import ImageDataGenerator

# Normalización de los datos.
import tensorflow as tf


def normalization(images, labels):
  images = tf.cast(images, tf.float32) # Esto genera un nuevo array con forma extraña xd.
  # La matriz pasa de estar separadas por coma, a cada fila estar unida y separada por puntos.
  images /= 255 # 255 es los valores de los pixeles. Básicamente

  

  return images, labels # No operamos las etiquetas pero igualmente queremos que
  # al pasar esta función nos devuelva una tupla.

print(len(train_data[0]))

t_data = normalization(train_data[0], train_data[1])
v_data = normalization(val_data[0], val_data[1])

import matplotlib.pyplot as plt


for label, train_image in enumerate(t_data[0]):
  plt.imshow(train_image, cmap='binary') # Descomentar si es necesario.

  if train_data[1][label] == 0:
    plt.title('Label: alt')

  elif train_data[1][label] == 1:
    plt.title('Label: y')

  elif train_data[1][label] == 2:
    plt.title('Label: n')

  elif train_data[1][label] == 3:
    plt.title('Label: h')


  plt.show() # Descomentar si es necesaio.
  break

import matplotlib.pyplot as plt


for label, val_image in enumerate(v_data[0]):
  plt.imshow(val_image, cmap='binary') # Descomentar si es necesario.

  if val_data[1][label] == 0:
    plt.title('Label: alt')

  elif val_data[1][label] == 1:
    plt.title('Label: y')

  elif val_data[1][label] == 2:
    plt.title('Label: n')

  elif val_data[1][label] == 3:
    plt.title('Label: h')

  break
  plt.show() # Descomentar si es necesaio.

# Model
model = tf.keras.Sequential([
    tf.keras.layers.Flatten(input_shape = (28, 28, 3)), # La capa flatten transforma la matriz en una matriz de una dimensión.
    tf.keras.layers.Dense(6, activation = tf.nn.relu), # Capa densa de 50 neuronas y 
    tf.keras.layers.Dense(6, activation = tf.nn.relu),
    # activación relu. Intentar cambiar la activación?? Las neuronas????
    tf.keras.layers.Dense(4, activation = tf.nn.softmax), # Capa con 4 salidas, para 
    # las predicciones y activación softmax, que a lo que nos ayuda es a obtener una sola predicción.
    # La red se estaría decidiendo solo por una etiqueta.
])

# Model compilation

model.compile(
    # TODO: Modificar un poco las capas y probar moviendo el learning rate.    
    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0009), # Variar esto puede suponer mejora.
    loss = tf.keras.losses.SparseCategoricalCrossentropy(),
    metrics = ['accuracy']

)

# LOTE_SIZE = 32 # Usar lotes??? Son muy pocos ejemplos.

history = model.fit(x=t_data[0], y=t_data[1], epochs = 118, validation_data = (v_data[0], v_data[1]), shuffle=True, batch_size=32) # Las epocas SON variables para un mejor resultado.

plt.xlabel('Epocas')
plt.ylabel('Peridida')
plt.plot(history.history['loss'])

plt.xlabel('Epocas')
plt.ylabel('Peridida')
plt.plot(history.history['val_loss'])

plt.xlabel('Epocas')
plt.ylabel('Precisión')
plt.plot(history.history['accuracy'])

plt.xlabel('Epocas')
plt.ylabel('Precisión')
plt.plot(history.history['val_accuracy'])

# Save model.
import datetime

now_time = str(datetime.datetime.now())[11:19]


model.save(f'/content/GTool Model Train - {now_time}.h5')